import feedparser
import tweepy
import requests
import os
import sys
import time
import re

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë° 'ê³µë°± ê°•ì œ ì œê±°'
# ==========================================
def get_clean_env(name):
    """ë¹„ë°€í‚¤ì— ë¶™ì€ ìˆ¨ê²¨ì§„ ê³µë°±, ì—”í„°í‚¤ë¥¼ ê°•ì œë¡œ ì‚­ì œí•¨"""
    val = os.environ.get(name)
    if val is None:
        print(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: GitHub Secretsì— '{name}' ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤!")
        return None
    # ê³µë°±, íƒ­, ì¤„ë°”ê¿ˆ ëª¨ë‘ ì œê±°
    clean_val = val.strip().replace('\n', '').replace('\r', '').replace(' ', '')
    
    # ë³´ì•ˆì„ ìœ„í•´ ì• 2ê¸€ìë§Œ ë³´ì—¬ì£¼ê³  ë‚˜ë¨¸ì§€ëŠ” ê°€ë¦¼
    masked = clean_val[:2] + "****" + clean_val[-2:] if len(clean_val) > 4 else "****"
    print(f"ğŸ”‘ {name} ë¡œë“œ ì™„ë£Œ: {masked} (ê¸¸ì´: {len(clean_val)})")
    return clean_val

print("--- ğŸ” ë¹„ë°€í‚¤ ì§„ë‹¨ ì‹œì‘ ---")
GEMINI_API_KEY = get_clean_env("GEMINI_API_KEY")
CONSUMER_KEY = get_clean_env("CONSUMER_KEY")
CONSUMER_SECRET = get_clean_env("CONSUMER_SECRET")
ACCESS_TOKEN = get_clean_env("ACCESS_TOKEN")
ACCESS_TOKEN_SECRET = get_clean_env("ACCESS_TOKEN_SECRET")
print("---------------------------")

# í‚¤ê°€ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
if not all([CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET]):
    print("âŒ ë¹„ë°€í‚¤ ë¡œë“œ ì‹¤íŒ¨. GitHub Settings > Secrets ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

# ==========================================
# 2. íŠ¸ìœ„í„° ì¸ì¦ (ì§„ë‹¨ ëª¨ë“œ)
# ==========================================
try:
    client = tweepy.Client(
        consumer_key=CONSUMER_KEY,
        consumer_secret=CONSUMER_SECRET,
        access_token=ACCESS_TOKEN,
        access_token_secret=ACCESS_TOKEN_SECRET
    )
    # ì¸ì¦ í…ŒìŠ¤íŠ¸: ë‚´ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹œë„ (v2)
    me = client.get_me()
    print(f"âœ… íŠ¸ìœ„í„° ë¡œê·¸ì¸ ì„±ê³µ! (ë´‡ ê³„ì •: {me.data.username})")
except Exception as e:
    print(f"âŒ íŠ¸ìœ„í„° ì¸ì¦ ì‚¬ë§: {e}")
    print("ğŸ‘‰ 401 ì—ëŸ¬ë¼ë©´: App Permissionsê°€ 'Read/Write'ì¸ì§€, í‚¤ë¥¼ ì¬ìƒì„± í–ˆëŠ”ì§€ í™•ì¸ í•„ìš”.")
    # ì¸ì¦ ì‹¤íŒ¨í•´ë„ ì¼ë‹¨ ë‰´ìŠ¤ ìˆ˜ì§‘ì€ ì‹œë„í•˜ë„ë¡ ë„˜ì–´ê° (ë¡œê·¸ í™•ì¸ìš©)

# ==========================================
# 3. ë‰´ìŠ¤ ì†ŒìŠ¤ ì„¤ì •
# ==========================================
RSS_US_INVESTING = "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=15839069"
RSS_US_FINANCE   = "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664"
RSS_US_TECH      = "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=19854910"
RSS_KR = "https://www.hankyung.com/feed/finance"

# ==========================================
# 4. ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ==========================================
def clean_html(raw_html):
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    return re.sub(cleanr, '', raw_html).strip()

def get_latest_news(rss_url):
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries: return None
        return feed.entries[0]
    except: return None

def check_if_new(last_link_file, current_link):
    if not os.path.exists(last_link_file): return True
    with open(last_link_file, 'r', encoding='utf-8') as f:
        return f.read().strip() != current_link

def save_current_link(last_link_file, current_link):
    with open(last_link_file, 'w', encoding='utf-8') as f:
        f.write(current_link)

def summarize_news(category, title, link):
    # ë¹„ìƒìš© ë¬´ë£Œ AI ëª¨ë¸ë“¤ ìˆœíšŒ
    models = ["gemini-1.5-flash", "gemini-pro"]
    
    prompt = f"ë‰´ìŠ¤ ì œëª©: {title}\në‰´ìŠ¤ ë§í¬: {link}\nì£¼ì‹ ë‰´ìŠ¤ 3ì¤„ ìš”ì•½ (í•´ìš”ì²´)."
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    for m in models:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{m}:generateContent?key={GEMINI_API_KEY}"
        try:
            res = requests.post(url, headers=headers, json=data)
            if res.status_code == 200:
                return res.json()['candidates'][0]['content']['parts'][0]['text']
        except: continue
    return None

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰
# ==========================================
def process_news(category_name, rss_url, last_link_file):
    print(f"\n--- [{category_name}] ---")
    news = get_latest_news(rss_url)
    if not news: return

    if check_if_new(last_link_file, news.link):
        print(f"âœ¨ ë°œê²¬: {news.title}")
        summary = summarize_news(category_name, news.title, news.link)
        
        if not summary:
            print("ğŸš¨ AI ì‹¤íŒ¨ -> ì›ë¬¸ ì œëª© ì‚¬ìš©")
            summary = f"{news.title}\n(AI ì˜¤ë¥˜ë¡œ ì œëª©ë§Œ ì „ì†¡)"

        tweet_text = f"[{category_name}] ğŸš¨\n\n{summary}\n\nğŸ”— {news.link}"
        
        try:
            client.create_tweet(text=tweet_text)
            print("âœ… ì—…ë¡œë“œ ì„±ê³µ!")
            save_current_link(last_link_file, news.link)
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print("ìƒˆ ë‰´ìŠ¤ ì—†ìŒ.")

if __name__ == "__main__":
    process_news("ë¯¸êµ­ì£¼ì‹(íˆ¬ì)", RSS_US_INVESTING, "last_link_us_investing.txt")
    time.sleep(1)
    process_news("ë¯¸êµ­ì£¼ì‹(ê¸ˆìœµ)", RSS_US_FINANCE, "last_link_us_finance.txt")
    time.sleep(1)
    process_news("ë¯¸êµ­ì£¼ì‹(ê¸°ìˆ )", RSS_US_TECH, "last_link_us_tech.txt")
    time.sleep(1)
    process_news("í•œêµ­ì£¼ì‹(í•œê²½)", RSS_KR, "last_link_kr.txt")
