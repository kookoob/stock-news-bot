import feedparser
import tweepy
import requests
import os
import sys
import time
import textwrap
import re
import shutil
from difflib import SequenceMatcher
from datetime import datetime, timedelta, timezone
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ==========================================
def get_clean_env(name):
    val = os.environ.get(name)
    if val is None: return None
    return val.strip().replace('\n', '').replace('\r', '').replace(' ', '')

GEMINI_API_KEY = get_clean_env("GEMINI_API_KEY")
CONSUMER_KEY = get_clean_env("CONSUMER_KEY")
CONSUMER_SECRET = get_clean_env("CONSUMER_SECRET")
ACCESS_TOKEN = get_clean_env("ACCESS_TOKEN")
ACCESS_TOKEN_SECRET = get_clean_env("ACCESS_TOKEN_SECRET")

# ==========================================
# 2. íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
# ==========================================
client = None
api = None
try:
    client = tweepy.Client(
        consumer_key=CONSUMER_KEY,
        consumer_secret=CONSUMER_SECRET,
        access_token=ACCESS_TOKEN,
        access_token_secret=ACCESS_TOKEN_SECRET
    )
    auth = tweepy.OAuth1UserHandler(
        CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET
    )
    api = tweepy.API(auth)
except Exception as e:
    print(f"âš ï¸ íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")

# ==========================================
# 3. ë‰´ìŠ¤ ì†ŒìŠ¤ ë¦¬ìŠ¤íŠ¸
# ==========================================
RSS_SOURCES = [
    # êµ­ì œ/ì „ìŸ ì†ë³´
    ("êµ­ì œì†ë³´(ì—°í•©)", "https://www.yna.co.kr/rss/international.xml", "last_link_yna_world.txt", "ì—°í•©ë‰´ìŠ¤"),
    ("ì „ìŸì†ë³´(êµ¬ê¸€)", "https://news.google.com/rss/search?q=ì „ìŸ+ì†ë³´+ë¯¸êµ­+ì´ë€&hl=ko&gl=KR&ceid=KR:ko", "last_link_google_war.txt", "Google News"),

    # ê²½ì œ/ì£¼ì‹ ë‰´ìŠ¤
    ("ë¯¸êµ­ì£¼ì‹(íˆ¬ì)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=15839069", "last_link_us_investing.txt", "CNBC"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸ˆìœµ)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664", "last_link_us_finance.txt", "CNBC"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸°ìˆ )", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=19854910", "last_link_us_tech.txt", "CNBC"),
    ("í•œêµ­ì£¼ì‹(í•œê²½)", "https://www.hankyung.com/feed/finance", "last_link_kr.txt", "í•œêµ­ê²½ì œ"),
    ("ë¯¸êµ­ì£¼ì‹(Yahoo)", "https://finance.yahoo.com/news/rssindex", "last_link_yahoo.txt", "Yahoo Finance"),
    ("ë¯¸êµ­ì£¼ì‹(Tech)", "https://techcrunch.com/feed/", "last_link_techcrunch.txt", "TechCrunch"),
    ("í•œêµ­ì£¼ì‹(ë§¤ê²½)", "https://www.mk.co.kr/rss/50200011/", "last_link_mk.txt", "ë§¤ì¼ê²½ì œ"),
    ("ë¯¸êµ­ì£¼ì‹(WSJ_Opinion)", "https://feeds.content.dowjones.io/public/rss/RSSOpinion", "last_link_wsj_op.txt", "WSJ"),
    ("ë¯¸êµ­ì£¼ì‹(WSJ_Market)", "https://feeds.content.dowjones.io/public/rss/RSSMarketsMain", "last_link_wsj_mkt.txt", "WSJ"),
    ("ë¯¸êµ­ì£¼ì‹(WSJ_Economy)", "https://feeds.content.dowjones.io/public/rss/socialeconomyfeed", "last_link_wsj_eco.txt", "WSJ"),
    ("ì†ë³´(í…”ë ˆê·¸ë¨)", "https://rsshub.app/telegram/channel/bornlupin", "last_link_bornlupin.txt", "Telegram"),
    ("í•œêµ­ì£¼ì‹(ì—°í•©)", "https://www.yna.co.kr/rss/economy.xml", "last_link_yna.txt", "ì—°í•©ë‰´ìŠ¤")
]

# ê¸°ì–µ ìš©ëŸ‰ 2000ê°œ (ì¤‘ë³µ ë°©ì§€ ê°•í™”)
MAX_HISTORY = 2000
GLOBAL_TITLE_FILE = "processed_global_titles.txt"

# ==========================================
# 4. ì‹œê°„ ì œì–´ í•¨ìˆ˜ (6ì‹œê°„ ì´ë‚´)
# ==========================================
def is_recent_news(entry):
    if not hasattr(entry, 'published_parsed') or not entry.published_parsed:
        return True
    try:
        published_time = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
        current_time = datetime.now(timezone.utc)
        time_diff = current_time - published_time
        
        if time_diff > timedelta(hours=6):
            print(f"â³ [ì˜¤ë˜ëœ ë‰´ìŠ¤] 6ì‹œê°„ ê²½ê³¼ë¡œ ìŠ¤í‚µ: {time_diff}")
            return False
        return True
    except:
        return True

# ==========================================
# 5. ì´ë¯¸ì§€ ë° AI ê´€ë ¨ í•¨ìˆ˜ (ë””ìì¸ ì—…ê·¸ë ˆì´ë“œ ë²„ì „)
# ==========================================
def create_gradient_background(width, height, start_color, end_color):
    """ì„¸ë ¨ëœ ìˆ˜ì§ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„± í•¨ìˆ˜"""
    base = Image.new('RGB', (width, height), start_color)
    top = Image.new('RGB', (width, height), end_color)
    mask = Image.new('L', (width, height))
    mask_data = []
    for y in range(height):
        mask_data.extend([int(255 * (y / height))] * width)
    mask.putdata(mask_data)
    base.paste(top, (0, 0), mask)
    return base

def create_info_image(text_lines, source_name):
    try:
        width, height = 1200, 675
        
        # --- ğŸ¨ ë””ìì¸ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ---
        bg_start = (10, 25, 45)   # ê¹Šì€ ë„¤ì´ë¹„ (ìƒë‹¨)
        bg_end = (20, 40, 70)     # ë°ì€ ë„¤ì´ë¹„ (í•˜ë‹¨)
        text_white = (245, 245, 250) # ë¶€ë“œëŸ¬ìš´ í°ìƒ‰
        text_gray = (180, 190, 210)  # ë°ì€ íšŒìƒ‰ (ë³´ì¡° í…ìŠ¤íŠ¸)
        accent_cyan = (0, 220, 255)  # í˜•ê´‘ í•˜ëŠ˜ìƒ‰ (ê°•ì¡°)
        title_box_bg = (0, 0, 0, 80) # ì œëª© ë°°ê²½ ë°˜íˆ¬ëª… ë°•ìŠ¤ (RGBA)

        # 1. ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„±
        image = create_gradient_background(width, height, bg_start, bg_end)
        draw = ImageDraw.Draw(image, 'RGBA') # RGBA ëª¨ë“œë¡œ ê·¸ë¦¬ê¸°

        # 2. í°íŠ¸ ë¡œë“œ (ì¤€ë¹„ë¬¼ì—ì„œ ì¤€ë¹„í•œ ë‘êº¼ìš´/ì¼ë°˜ í°íŠ¸)
        try:
            # ì œëª©ìš© ë‘êº¼ìš´ í°íŠ¸
            font_title_main = ImageFont.truetype("font_bold.ttf", 60) 
            # ë³¸ë¬¸ìš© ì¼ë°˜ í°íŠ¸
            font_body = ImageFont.truetype("font_reg.ttf", 34)
            # ìƒë‹¨ í—¤ë”ìš© ì‘ì€ í°íŠ¸
            font_header = ImageFont.truetype("font_bold.ttf", 26)
             # ë‚ ì§œìš© ì‘ì€ í°íŠ¸
            font_date = ImageFont.truetype("font_reg.ttf", 26)
        except:
            print("âš ï¸ ìƒˆ í°íŠ¸ íŒŒì¼(font_bold.ttf, font_reg.ttf)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¡´ font.ttfë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
            try:
                font_title_main = ImageFont.truetype("font.ttf", 60)
                font_body = ImageFont.truetype("font.ttf", 34)
                font_header = ImageFont.truetype("font.ttf", 26)
                font_date = ImageFont.truetype("font.ttf", 26)
            except: return None

        margin_x = 60
        current_y = 40

        # --- ìƒë‹¨ í—¤ë” (Market Radar | ë‚ ì§œ) ---
        header_text = "MARKET RADAR"
        if source_name:
            header_text += f" | {source_name}"
        
        # í—¤ë”ì— ì‘ì€ í¬ì¸íŠ¸ ì•„ì´ì½˜ ê·¸ë¦¬ê¸° (íŒŒë€ ì )
        draw.ellipse([(margin_x, current_y+8), (margin_x+12, current_y+20)], fill=accent_cyan)
        draw.text((margin_x + 25, current_y), header_text, font=font_header, fill=accent_cyan)

        KST = timezone(timedelta(hours=9))
        now = datetime.now(KST)
        date_str = f"{now.year}.{now.month:02d}.{now.day:02d} | @marketradar0"
        
        # ë‚ ì§œ ì˜¤ë¥¸ìª½ ì •ë ¬ ê³„ì‚°
        date_bbox = draw.textbbox((0, 0), date_str, font=font_date)
        date_width = date_bbox[2] - date_bbox[0]
        draw.text((width - margin_x - date_width, current_y), date_str, font=font_date, fill=text_gray)
        
        current_y += 70 # í—¤ë” ì•„ë˜ ì—¬ë°±

        # --- ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ ---
        for i, line in enumerate(text_lines):
            line = line.strip().replace("**", "").replace("##", "")
            if not line: continue

            if i == 0: 
                # â˜… ì²« ì¤„: ë©”ì¸ ì œëª© (ê°•ì¡° ë°•ìŠ¤ + í° í°íŠ¸)
                wrapped_title = textwrap.wrap(line, width=20) # ì œëª© ì¤„ë°”ê¿ˆ í­ ì¡°ì ˆ
                
                # ì œëª© ë°•ìŠ¤ ë†’ì´ ê³„ì‚°
                title_box_height = len(wrapped_title) * 85 + 30
                # ë°˜íˆ¬ëª… ì œëª© ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                draw.rectangle([(margin_x - 20, current_y), (width - margin_x + 20, current_y + title_box_height)], fill=title_box_bg)
                
                current_y += 20 # ë°•ìŠ¤ ë‚´ë¶€ íŒ¨ë”©
                for wl in wrapped_title:
                    draw.text((margin_x, current_y), wl, font=font_title_main, fill=text_white)
                    current_y += 85
                current_y += 40 # ì œëª© ì•„ë˜ ì—¬ë°±
                
            else: 
                # â˜… ë‚˜ë¨¸ì§€ ì¤„: ë³¸ë¬¸ ìš”ì•½ (ì„¸ë ¨ëœ ë¶ˆë¦¿ í¬ì¸íŠ¸)
                # ì„¸ë ¨ëœ í™”ì‚´í‘œ ëª¨ì–‘ ë¶ˆë¦¿ (â–º)
                bullet_text = "â–º"
                draw.text((margin_x, current_y + 2), bullet_text, font=font_header, fill=accent_cyan)
                
                wrapped_body = textwrap.wrap(line, width=40) # ë³¸ë¬¸ ì¤„ë°”ê¿ˆ í­ ì¡°ì ˆ
                for wl in wrapped_body:
                    draw.text((margin_x + 35, current_y), wl, font=font_body, fill=text_white)
                    current_y += 48 # ì¤„ê°„ê²©
                current_y += 15 # ë¬¸ë‹¨ ê°„ê²©

            if current_y > height - 60: break # ë†’ì´ ì´ˆê³¼ ì‹œ ì¤‘ë‹¨

        # í•˜ë‹¨ì— ì–‡ì€ ê°•ì¡°ì„  í•˜ë‚˜ ì¶”ê°€
        draw.rectangle([(margin_x, height - 20), (width - margin_x, height - 18)], fill=accent_cyan)

        temp_filename = "temp_card_16_9.png"
        image.convert("RGB").save(temp_filename) # ì €ì¥í•  ë•ŒëŠ” RGBë¡œ ë³€í™˜
        return temp_filename
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì—ëŸ¬: {e}")
        return None

# â˜… [ë¹„ìš© ì ˆê° í•µì‹¬] ê°€ì¥ ì €ë ´í•œ ëª¨ë¸(Flash) ê°•ì œ ê³ ì •
def get_working_model():
    return "gemini-1.5-flash"

def summarize_news(target_model, title, link, content_text=""):
    prompt = f"""
    ë‰´ìŠ¤ ì œëª©: {title}
    ë‰´ìŠ¤ ë§í¬: {link}
    ë‰´ìŠ¤ ë‚´ìš©(Raw): {content_text}
    ë¶„ì„ í›„ íŠ¸ìœ„í„° ë³¸ë¬¸, ì¸í¬ê·¸ë˜í”½ í…ìŠ¤íŠ¸, ì›ì²œ ì†ŒìŠ¤ë¥¼ ì°¾ì•„ì¤˜.
    [ì‘ì„± ê·œì¹™ 1: íŠ¸ìœ„í„° ë³¸ë¬¸]
    - ---BODY--- ì•„ë˜ ì‘ì„±. X í”„ë¦¬ë¯¸ì—„ìš© ì¥ë¬¸ ìƒì„¸ ìš”ì•½. í•œêµ­ì–´ ë²ˆì—­ í•„ìˆ˜. ëª…ì‚¬í˜• ì¢…ê²°/ìŒìŠ´ì²´.
    - êµ¬ì„±: ì œëª©(ì´ëª¨ì§€+í•œê¸€), ìƒì„¸ ë‚´ìš©(âœ… ì²´í¬í¬ì¸íŠ¸), í•˜ë‹¨ í‹°ì»¤($)+í•´ì‹œíƒœê·¸(#)
    - â˜… ì¤‘ìš”: ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ë¼ë©´ í•´ì‹œíƒœê·¸ì— #ì£¼ì‹ ë°˜ë“œì‹œ í¬í•¨.
    [ì‘ì„± ê·œì¹™ 2: ì¸í¬ê·¸ë˜í”½ ì´ë¯¸ì§€]
    - ---IMAGE--- ì•„ë˜ ì‘ì„±.
    - êµ¬ì„±: ì²« ì¤„ ê°•ë ¬í•œ í•œê¸€ ì œëª©(í•µì‹¬ ìˆ˜ì¹˜ í¬í•¨, ì´ëª¨ì§€X). ë‚˜ë¨¸ì§€ í•µì‹¬ ìš”ì•½ 7ë¬¸ì¥ ì´ë‚´.
    [ì‘ì„± ê·œì¹™ 3: ì›ì²œ ì†ŒìŠ¤]
    - ---SOURCE--- ì•„ë˜ ì‘ì„±. ì–¸ë¡ ì‚¬ ì´ë¦„ë§Œ. ì—†ìœ¼ë©´ Unknown.
    [ê¸ˆì§€ì‚¬í•­] ë§ˆí¬ë‹¤ìš´(**, ##) ê¸ˆì§€.
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{target_model}:generateContent?key={GEMINI_API_KEY}"
    data = {"contents": [{"parts": [{"text": prompt}]}], "safetySettings": [{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}]}
    headers = {'Content-Type': 'application/json'}
    for _ in range(2): # ì¬ì‹œë„ íšŸìˆ˜ë„ 2íšŒë¡œ ì¤„ì—¬ ë¹„ìš© ë°©ì–´
        try:
            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 200:
                full_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                if "---BODY---" in full_text and "---IMAGE---" in full_text:
                    parts = full_text.split("---IMAGE---")
                    body_raw = parts[0].replace("---BODY---", "").strip()
                    remaining = parts[1]
                    if "---SOURCE---" in remaining:
                        img_parts = remaining.split("---SOURCE---")
                        image_raw = img_parts[0].strip()
                        source_raw = img_parts[1].strip()
                    else: image_raw = remaining.strip(); source_raw = "Unknown"
                    body_part = body_raw.replace("**", "").replace("##", "")
                    image_lines = [re.sub(r"^[\-\*\â€¢\Â·\âœ…\âœ”\â–ª\â–«\â–º]+\s*", "", re.sub(r"^\d+\.\s+", "", l.strip().replace("**", "").replace("##", ""))) for l in image_raw.split('\n') if l.strip()]
                    source_name = source_raw.split('\n')[0].strip()
                    if "Unknown" in source_name or len(source_name) > 20: source_name = None
                    return body_part, image_lines, source_name
                return None, None, None
            elif response.status_code == 429: time.sleep(60); continue
            else: return None, None, None
        except: return None, None, None
    return None, None, None

# ==========================================
# 6. ê¸°ë¡ ê´€ë¦¬ (ìµœëŒ€ 2000ê°œ)
# ==========================================
def get_processed_links(filename):
    if not os.path.exists(filename): return []
    with open(filename, 'r', encoding='utf-8') as f: return [line.strip() for line in f.readlines()]

def save_processed_link(filename, link):
    links = get_processed_links(filename)
    clean_link = link.strip()
    if clean_link not in links:
        links.append(clean_link)
        if len(links) > MAX_HISTORY: links = links[-MAX_HISTORY:]
        with open(filename, 'w', encoding='utf-8') as f: f.write("\n".join(links))

def get_global_titles():
    if not os.path.exists(GLOBAL_TITLE_FILE): return []
    with open(GLOBAL_TITLE_FILE, 'r', encoding='utf-8') as f: return [line.strip() for line in f.readlines()]

def save_global_title(title):
    titles = get_global_titles()
    clean_title = re.sub(r'\s+', ' ', title).strip()
    if clean_title not in titles:
        titles.append(clean_title)
        if len(titles) > MAX_HISTORY: titles = titles[-MAX_HISTORY:]
        with open(GLOBAL_TITLE_FILE, 'w', encoding='utf-8') as f: f.write("\n".join(titles))

def is_similar_title(new_title, existing_titles):
    clean_new = re.sub(r'\s+', ' ', new_title).strip()
    for old_title in existing_titles:
        if SequenceMatcher(None, clean_new, old_title).ratio() > 0.6: 
            print(f"ğŸš« ì¤‘ë³µ ê°ì§€ (ìœ ì‚¬ë„): {clean_new} <-> {old_title}")
            return True
    return False

# ==========================================
# 7. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (â˜… ë¹„ìš© ì ˆê° ë¡œì§ ì ìš©)
# ==========================================
if __name__ == "__main__":
    # â˜… ëª¨ë¸ ê³ ì • (Flash)
    current_model = "gemini-1.5-flash"
    global_titles = get_global_titles()
    
    for category, rss_url, filename, default_source_name in RSS_SOURCES:
        print(f"\n--- [{category}] ---")
        
        try:
            feed = feedparser.parse(rss_url)
            if not feed.entries: print("ë‰´ìŠ¤ ì—†ìŒ"); continue
            news = feed.entries[0]
        except: print("RSS íŒŒì‹± ì‹¤íŒ¨"); continue
        
        # 6ì‹œê°„ ì´ë‚´ ì²´í¬
        if not is_recent_news(news):
            continue

        # â˜… [ë¹„ìš© ì ˆê° 1] ë§í¬ ì¤‘ë³µ ì‹œ API í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ì¢…ë£Œ
        processed_links = get_processed_links(filename)
        if news.link.strip() in processed_links: 
            print("ğŸ’° [ë¹„ìš© ì ˆê°] ì´ë¯¸ ì²˜ë¦¬ëœ ë§í¬. API í˜¸ì¶œ ìƒëµ."); continue

        check_title = news.title if news.title else (news.description[:50] if hasattr(news, 'description') else "")
        
        # â˜… [ë¹„ìš© ì ˆê° 2] ì œëª© ì¤‘ë³µ ì‹œ API í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ì¢…ë£Œ
        if is_similar_title(check_title, global_titles):
            print("ğŸ’° [ë¹„ìš© ì ˆê°] ì¤‘ë³µ ë‚´ìš© ê°ì§€. API í˜¸ì¶œ ìƒëµ."); 
            save_processed_link(filename, news.link); # ë§í¬ë§Œ ì €ì¥í•´ë‘ 
            continue

        print(f"âœ¨ ìƒˆ ë‰´ìŠ¤ ë°œê²¬ (AI ë¶„ì„ ì‹œì‘): {news.title}")
        
        # --- ì—¬ê¸°ì„œë¶€í„° ëˆì´ ë‚˜ê°€ëŠ” êµ¬ê°„ ---
        real_link = news.link
        content_for_ai = ""
        if hasattr(news, 'description'):
            content_for_ai = news.description
            if "í…”ë ˆê·¸ë¨" in category:
                urls = re.findall(r'(https?://\S+)', content_for_ai)
                if urls: real_link = urls[0]

        body_text, img_lines, detected_source = summarize_news(current_model, news.title, real_link, content_for_ai)
        
        if body_text and img_lines:
            final_source_name = detected_source if "í…”ë ˆê·¸ë¨" in category else default_source_name
            image_file = create_info_image(img_lines, final_source_name)
            
            try:
                media_id = None
                if image_file: media = api.media_upload(image_file); media_id = media.media_id
                
                final_tweet = body_text if not final_source_name else f"{body_text}\n\nì¶œì²˜: {final_source_name}"
                
                # #ì£¼ì‹ í•´ì‹œíƒœê·¸ ì¶”ê°€
                if "ì£¼ì‹" in category and "#ì£¼ì‹" not in final_tweet:
                    final_tweet += " #ì£¼ì‹"
                
                if len(final_tweet) > 12000: final_tweet = final_tweet[:11995] + "..."
                if media_id: response = client.create_tweet(text=final_tweet, media_ids=[media_id])
                else: response = client.create_tweet(text=final_tweet)
                tweet_id = response.data['id']
                print("âœ… ì—…ë¡œë“œ ì„±ê³µ")
                client.create_tweet(text=f"ğŸ”— ì›ë¬¸ ê¸°ì‚¬:\n{real_link}", in_reply_to_tweet_id=tweet_id)
                
                # ì„±ê³µ í›„ ê¸°ë¡ ì €ì¥
                save_processed_link(filename, news.link)
                save_global_title(check_title)
                global_titles.append(re.sub(r'\s+', ' ', check_title).strip())
            except Exception as e: print(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}")
            if image_file and os.path.exists(image_file): os.remove(image_file)
        else: print("ğŸš¨ ìš”ì•½ ì‹¤íŒ¨")
        time.sleep(2)

