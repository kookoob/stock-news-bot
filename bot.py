import feedparser
import tweepy
import requests
import os
import sys
import time
import re

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ==========================================
def get_clean_env(name):
    val = os.environ.get(name)
    if val is None: return None
    return val.strip().replace('\n', '').replace('\r', '').replace(' ', '')

GEMINI_API_KEY = get_clean_env("GEMINI_API_KEY")
CONSUMER_KEY = get_clean_env("CONSUMER_KEY")
CONSUMER_SECRET = get_clean_env("CONSUMER_SECRET")
ACCESS_TOKEN = get_clean_env("ACCESS_TOKEN")
ACCESS_TOKEN_SECRET = get_clean_env("ACCESS_TOKEN_SECRET")

# ==========================================
# 2. íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸
# ==========================================
client = None
try:
    client = tweepy.Client(
        consumer_key=CONSUMER_KEY,
        consumer_secret=CONSUMER_SECRET,
        access_token=ACCESS_TOKEN,
        access_token_secret=ACCESS_TOKEN_SECRET
    )
except:
    print("âš ï¸ íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì˜¤ë¥˜")

# ==========================================
# 3. ë‰´ìŠ¤ ì†ŒìŠ¤ ì„¤ì • (ë§¤ì¼ê²½ì œ ë§í¬ êµì²´ë¨)
# ==========================================
RSS_SOURCES = [
    ("ë¯¸êµ­ì£¼ì‹(íˆ¬ì)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=15839069", "last_link_us_investing.txt", "CNBC"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸ˆìœµ)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664", "last_link_us_finance.txt", "CNBC"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸°ìˆ )", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=19854910", "last_link_us_tech.txt", "CNBC"),
    ("í•œêµ­ì£¼ì‹(í•œê²½)", "https://www.hankyung.com/feed/finance", "last_link_kr.txt", "í•œêµ­ê²½ì œ"),
    ("ë¯¸êµ­ì£¼ì‹(Yahoo)", "https://finance.yahoo.com/news/rssindex", "last_link_yahoo.txt", "Yahoo Finance"),
    ("ë¯¸êµ­ì£¼ì‹(MW)", "http://feeds.marketwatch.com/marketwatch/topstories/", "last_link_mw.txt", "MarketWatch"),
    ("ë¯¸êµ­ì£¼ì‹(Tech)", "https://techcrunch.com/feed/", "last_link_techcrunch.txt", "TechCrunch"),
    
    # [ìˆ˜ì •ë¨] ë§¤ì¼ê²½ì œ RSS ë§í¬ êµì²´ (30100041 -> 50200011)
    ("í•œêµ­ì£¼ì‹(ë§¤ê²½)", "https://www.mk.co.kr/rss/50200011/", "last_link_mk.txt", "ë§¤ì¼ê²½ì œ")
]

# ==========================================
# 4. AI ìš”ì•½ í•¨ìˆ˜ (ì¥ë¬¸ í”„ë¦¬ë¯¸ì—„ ëª¨ë“œ)
# ==========================================
def summarize_news(category, title, link):
    list_url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}"
    target_model = "gemini-1.5-flash"

    try:
        list_res = requests.get(list_url)
        if list_res.status_code == 200:
            models = list_res.json().get('models', [])
            for m in models:
                if 'generateContent' in m.get('supportedGenerationMethods', []):
                    target_model = m['name'].replace('models/', '')
                    break
    except: pass

    # AI í”„ë¡¬í”„íŠ¸: ìƒì„¸ ë¶„ì„ ë° ì¥ë¬¸ ì‘ì„± ìš”êµ¬
    prompt = f"""
    ë‰´ìŠ¤ ì œëª©: {title}
    ë‰´ìŠ¤ ë§í¬: {link}

    ìœ„ ë‰´ìŠ¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ íŠ¸ìœ„í„°(X) í”„ë¦¬ë¯¸ì—„ìš© ì¥ë¬¸ í¬ìŠ¤íŒ…ì„ ì‘ì„±í•´ì¤˜.
    
    [ì‘ì„± ê·œì¹™]
    1. ì²«ì§¸ ì¤„: ê¸°ì‚¬ì˜ ì›ë˜ ì œëª©ì„ 'í•œêµ­ì–´'ë¡œ ì™„ë²½í•˜ê²Œ ë²ˆì—­í•´ì„œ ì ì„ ê²ƒ. (ì´ëª¨ì§€ 1ê°œ í¬í•¨)
    2. ë³¸ë¬¸:
       - ê¸€ì ìˆ˜ì— êµ¬ì• ë°›ì§€ ë§ê³ , ê¸°ì‚¬ì˜ ë‚´ìš©ì„ **ìµœëŒ€í•œ ìƒì„¸í•˜ê²Œ** ì‘ì„±í•  ê²ƒ.
       - ê¸°ì‚¬ì— í¬í•¨ëœ ëª¨ë“  **êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ë°ì´í„°, ê¸°ì—…ëª…**ì„ ë¹ ì§ì—†ì´ í¬í•¨í•  ê²ƒ.
       - ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, ì´ ë‰´ìŠ¤ê°€ ì‹œì¥ì— ë¯¸ì¹  ì˜í–¥ì´ë‚˜ ë°°ê²½ê¹Œì§€ ê¹Šì´ ìˆê²Œ ì„¤ëª…í•  ê²ƒ.
       - ê°€ë…ì„±ì„ ìœ„í•´ ë¬¸ë‹¨(ì—”í„°)ì„ ìì£¼ ë‚˜ëˆ„ê³ , ê¸€ ë¨¸ë¦¬ ê¸°í˜¸(âœ…, ğŸ‘‰ ë“±)ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•  ê²ƒ.
       - ì¶•ì•½ì²´ë¥¼ ì‚¬ìš©í•˜ë˜(í•¨, ìŒ, ë“±), ì „ë¬¸ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•  ê²ƒ.
       - ë³¸ë¬¸ í•˜ë‹¨ì—ëŠ” ê´€ë ¨ ì£¼ì‹ì˜ í‹°ì»¤($)ë¥¼ ë‹¬ ê²ƒ. ê¸°ì‚¬ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰ëœ íšŒì‚¬ì˜ ì£¼ì‹ì€ ì ˆëŒ€ ë¹ íŠ¸ë¦¬ì§€ ë§ ê²ƒ.
       - í•´ì‹œíƒœê·¸(#)ëŠ” ê¸°ì‚¬ì—ì„œ ë©”ì¸ì´ ë˜ëŠ” íšŒì‚¬ì´ë¦„, ì¸ë¬¼ì´ë¦„, ê¸°ì—…ì´ë¦„ ì •ë„ë§Œ 3ê°œ ì´ë‚´ë¡œ ë‹¬ ê²ƒ.
    3. ë§í¬ë‚˜ URLì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ (ëŒ“ê¸€ë¡œ ë‹¬ ì˜ˆì •).
    """

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{target_model}:generateContent?key={GEMINI_API_KEY}"
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        return None
    except: return None

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰ (í”„ë¦¬ë¯¸ì—„ 12,500ì ì œí•œ)
# ==========================================
def get_latest_news(rss_url):
    try:
        feed = feedparser.parse(rss_url)
        return feed.entries[0] if feed.entries else None
    except: return None

def check_if_new(last_link_file, current_link):
    if not os.path.exists(last_link_file): return True
    with open(last_link_file, 'r', encoding='utf-8') as f:
        return f.read().strip() != current_link

def save_current_link(last_link_file, current_link):
    with open(last_link_file, 'w', encoding='utf-8') as f:
        f.write(current_link)

if __name__ == "__main__":
    for category, rss_url, filename, source_name in RSS_SOURCES:
        print(f"\n--- [{category}] ---")
        news = get_latest_news(rss_url)
        
        if news and check_if_new(filename, news.link):
            print(f"âœ¨ ë‰´ìŠ¤ ë°œê²¬: {news.title}")
            
            summary = summarize_news(category, news.title, news.link)
            
            if summary:
                tweet_text = f"{summary}\n\nì¶œì²˜: {source_name}"
                
                # í”„ë¦¬ë¯¸ì—„ í•œë„(í•œê¸€ 12,500ì) ì ìš© (ì•ˆì „í•˜ê²Œ 12,000ì ì»·)
                if len(tweet_text) > 12000:
                    tweet_text = tweet_text[:11995] + "..."
                
                try:
                    # 1. ë©”ì¸ íŠ¸ìœ— ì—…ë¡œë“œ
                    response = client.create_tweet(text=tweet_text)
                    tweet_id = response.data['id']
                    print("âœ… ë©”ì¸ íŠ¸ìœ— ì—…ë¡œë“œ ì„±ê³µ!")
                    
                    # 2. ë§í¬ ëŒ“ê¸€ ë‹¬ê¸°
                    reply_text = f"ğŸ”— ì›ë¬¸ ê¸°ì‚¬ ë³´ëŸ¬ê°€ê¸°:\n{news.link}"
                    client.create_tweet(text=reply_text, in_reply_to_tweet_id=tweet_id)
                    print("âœ… ë§í¬ ëŒ“ê¸€ ë‹¬ê¸° ì„±ê³µ!")

                    save_current_link(filename, news.link)
                    
                except Exception as e:
                    print(f"âŒ íŠ¸ìœ— ì‹¤íŒ¨: {e}")
                    if "too long" in str(e).lower():
                         print("ğŸ‘‰ ë´‡ ê³„ì •ì´ 'í”„ë¦¬ë¯¸ì—„'ì´ ì•„ë‹ˆë©´ ê¸´ ê¸€ì„ ì˜¬ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("ğŸš¨ AI ìš”ì•½ ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœ€")
        else:
            print("ìƒˆ ë‰´ìŠ¤ ì—†ìŒ.")
        time.sleep(2)

