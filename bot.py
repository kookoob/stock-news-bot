import feedparser
import tweepy
import requests
import os
import sys
import time
import textwrap
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ==========================================
def get_clean_env(name):
    val = os.environ.get(name)
    if val is None: return None
    return val.strip().replace('\n', '').replace('\r', '').replace(' ', '')

GEMINI_API_KEY = get_clean_env("GEMINI_API_KEY")
CONSUMER_KEY = get_clean_env("CONSUMER_KEY")
CONSUMER_SECRET = get_clean_env("CONSUMER_SECRET")
ACCESS_TOKEN = get_clean_env("ACCESS_TOKEN")
ACCESS_TOKEN_SECRET = get_clean_env("ACCESS_TOKEN_SECRET")

# ==========================================
# 2. íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸
# ==========================================
client = None
api = None
try:
    client = tweepy.Client(
        consumer_key=CONSUMER_KEY,
        consumer_secret=CONSUMER_SECRET,
        access_token=ACCESS_TOKEN,
        access_token_secret=ACCESS_TOKEN_SECRET
    )
    auth = tweepy.OAuth1UserHandler(
        CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET
    )
    api = tweepy.API(auth)
except:
    print("âš ï¸ íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì˜¤ë¥˜")

# ==========================================
# 3. ë‰´ìŠ¤ ì†ŒìŠ¤ ì„¤ì •
# ==========================================
RSS_SOURCES = [
    ("ë¯¸êµ­ì£¼ì‹(íˆ¬ì)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=15839069", "last_link_us_investing.txt", "CNBC"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸ˆìœµ)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664", "last_link_us_finance.txt", "CNBC"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸°ìˆ )", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=19854910", "last_link_us_tech.txt", "CNBC"),
    ("í•œêµ­ì£¼ì‹(í•œê²½)", "https://www.hankyung.com/feed/finance", "last_link_kr.txt", "í•œêµ­ê²½ì œ"),
    ("ë¯¸êµ­ì£¼ì‹(Yahoo)", "https://finance.yahoo.com/news/rssindex", "last_link_yahoo.txt", "Yahoo Finance"),
    ("ë¯¸êµ­ì£¼ì‹(Tech)", "https://techcrunch.com/feed/", "last_link_techcrunch.txt", "TechCrunch"),
    ("í•œêµ­ì£¼ì‹(ë§¤ê²½)", "https://www.mk.co.kr/rss/50200011/", "last_link_mk.txt", "ë§¤ì¼ê²½ì œ"),
    ("ë¯¸êµ­ì£¼ì‹(WSJ_Opinion)", "https://feeds.content.dowjones.io/public/rss/RSSOpinion", "last_link_wsj_op.txt", "WSJ"),
    ("ë¯¸êµ­ì£¼ì‹(WSJ_Market)", "https://feeds.content.dowjones.io/public/rss/RSSMarketsMain", "last_link_wsj_mkt.txt", "WSJ"),
    ("ë¯¸êµ­ì£¼ì‹(WSJ_Economy)", "https://feeds.content.dowjones.io/public/rss/socialeconomyfeed", "last_link_wsj_eco.txt", "WSJ")
]

# ==========================================
# 4. ì¹´ë“œë‰´ìŠ¤ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
# ==========================================
def create_info_image(text, source_name):
    try:
        width, height = 1080, 1080
        background_color = (20, 20, 20)
        text_color = (255, 255, 255)
        accent_color = (0, 180, 255)
        
        image = Image.new('RGB', (width, height), background_color)
        draw = ImageDraw.Draw(image)
        
        font_path = "font.ttf"
        try:
            title_font = ImageFont.truetype(font_path, 60)
            body_font = ImageFont.truetype(font_path, 40)
            source_font = ImageFont.truetype(font_path, 30)
        except:
            print("âš ï¸ í°íŠ¸ íŒŒì¼(font.ttf) ì—†ìŒ! ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í•œê¸€ ê¹¨ì§ ì£¼ì˜)")
            return None

        margin = 80
        current_h = 100
        
        draw.text((margin, 50), f"Market Radar | {source_name}", font=source_font, fill=accent_color)

        lines = text.split('\n')
        for line in lines:
            if lines.index(line) == 0:
                wrapped_lines = textwrap.wrap(line, width=28)
                for wl in wrapped_lines:
                    draw.text((margin, current_h), wl, font=title_font, fill=accent_color)
                    current_h += 80
                current_h += 40
                draw.line([(margin, current_h), (width-margin, current_h)], fill=(100,100,100), width=2)
                current_h += 60
            else:
                wrapped_lines = textwrap.wrap(line, width=40)
                for wl in wrapped_lines:
                    draw.text((margin, current_h), wl, font=body_font, fill=text_color)
                    current_h += 55
            
            if current_h > height - 100:
                break
                
        temp_filename = "temp_news_card.png"
        image.save(temp_filename)
        return temp_filename
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì—ëŸ¬: {e}")
        return None

# ==========================================
# 5. AI ìš”ì•½ í•¨ìˆ˜ (ì—ëŸ¬ ì¶œë ¥ + ì•ˆì „í•„í„° í•´ì œ)
# ==========================================
def summarize_news(category, title, link):
    list_url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}"
    target_model = "gemini-1.5-flash"

    try:
        list_res = requests.get(list_url)
        if list_res.status_code == 200:
            models = list_res.json().get('models', [])
            for m in models:
                if 'generateContent' in m.get('supportedGenerationMethods', []):
                    target_model = m['name'].replace('models/', '')
                    break
    except: pass

    prompt = f"""
    ë‰´ìŠ¤ ì œëª©: {title}
    ë‰´ìŠ¤ ë§í¬: {link}

    ì´ ë‰´ìŠ¤ë¥¼ 'ì¹´ë“œë‰´ìŠ¤ ì´ë¯¸ì§€'ì— ë„£ì„ ìˆ˜ ìˆë„ë¡ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•´ì¤˜.
    
    [ì‘ì„± ê·œì¹™]
    1. ì²«ì§¸ ì¤„: í•µì‹¬ ì œëª© (ì´ëª¨ì§€ ì—†ì´ í•œê¸€ë¡œë§Œ, ì„íŒ©íŠ¸ ìˆê²Œ)
    2. ë³¸ë¬¸:
       - 4~5ê°œì˜ í•µì‹¬ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ (ê°œì¡°ì‹)
       - êµ¬ì²´ì  ìˆ˜ì¹˜($) í¬í•¨ í•„ìˆ˜
       - 'âœ…' ê°™ì€ ë¶ˆë ›í¬ì¸íŠ¸ ì‚¬ìš©
       - ë¬¸ì¥ì€ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ
    3. ë§¨ ì•„ë˜ì¤„: ê´€ë ¨ í‹°ì»¤ ($TSLA ë“±) ë° í•´ì‹œíƒœê·¸ 2ê°œ
    4. ë§í¬ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€
    """

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{target_model}:generateContent?key={GEMINI_API_KEY}"
    
    # â˜… ìˆ˜ì •ë¨: ì•ˆì „ ì„¤ì •(Safety Settings) ì¶”ê°€ -> ì°¨ë‹¨ ë°©ì§€
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
    }
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(url, headers=headers, json=data)
        
        # â˜… ìˆ˜ì •ë¨: ì—ëŸ¬ê°€ ë‚˜ë©´ ì •í™•í•œ ì´ìœ ë¥¼ ì¶œë ¥í•˜ë„ë¡ ë³€ê²½
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            print(f"ğŸš¨ API í˜¸ì¶œ ì—ëŸ¬ (ì½”ë“œ {response.status_code}): {response.text}")
            return None
            
    except Exception as e:
        print(f"ğŸš¨ ì—°ê²° ì—ëŸ¬: {e}")
        return None

# ==========================================
# 6. ë©”ì¸ ì‹¤í–‰
# ==========================================
def get_latest_news(rss_url):
    try:
        feed = feedparser.parse(rss_url)
        return feed.entries[0] if feed.entries else None
    except: return None

def check_if_new(last_link_file, current_link):
    if not os.path.exists(last_link_file): return True
    with open(last_link_file, 'r', encoding='utf-8') as f:
        return f.read().strip() != current_link

def save_current_link(last_link_file, current_link):
    with open(last_link_file, 'w', encoding='utf-8') as f:
        f.write(current_link)

if __name__ == "__main__":
    for category, rss_url, filename, source_name in RSS_SOURCES:
        print(f"\n--- [{category}] ---")
        news = get_latest_news(rss_url)
        
        if news and check_if_new(filename, news.link):
            print(f"âœ¨ ë‰´ìŠ¤ ë°œê²¬: {news.title}")
            
            summary = summarize_news(category, news.title, news.link)
            
            if summary:
                image_file = create_info_image(summary, source_name)
                
                try:
                    media_id = None
                    if image_file:
                        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ, ì—…ë¡œë“œ ì¤‘...")
                        media = api.media_upload(image_file)
                        media_id = media.media_id
                    
                    tweet_text = f"[{category}]\n\n{summary}\n\nì¶œì²˜: {source_name}"
                    
                    if len(tweet_text) > 12000:
                        tweet_text = tweet_text[:11995] + "..."

                    if media_id:
                        response = client.create_tweet(text=tweet_text, media_ids=[media_id])
                    else:
                        response = client.create_tweet(text=tweet_text)
                        
                    tweet_id = response.data['id']
                    print("âœ… ë©”ì¸ íŠ¸ìœ— ì—…ë¡œë“œ ì„±ê³µ!")
                    
                    reply_text = f"ğŸ”— ì›ë¬¸ ê¸°ì‚¬ ë³´ëŸ¬ê°€ê¸°:\n{news.link}"
                    client.create_tweet(text=reply_text, in_reply_to_tweet_id=tweet_id)
                    print("âœ… ë§í¬ ëŒ“ê¸€ ë‹¬ê¸° ì„±ê³µ!")

                    save_current_link(filename, news.link)
                    
                    if image_file and os.path.exists(image_file):
                        os.remove(image_file)
                    
                except Exception as e:
                    print(f"âŒ íŠ¸ìœ— ì‹¤íŒ¨: {e}")
            else:
                print("ğŸš¨ AI ìš”ì•½ ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœ€ (ìœ„ ì—ëŸ¬ ë¡œê·¸ í™•ì¸ í•„ìš”)")
        else:
            print("ìƒˆ ë‰´ìŠ¤ ì—†ìŒ.")
        time.sleep(2)
