import feedparser
import tweepy
import requests
import os
import sys
import time
import re

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ê³µë°± ì œê±°)
# ==========================================
def get_clean_env(name):
    val = os.environ.get(name)
    if val is None: return None
    return val.strip().replace('\n', '').replace('\r', '').replace(' ', '')

GEMINI_API_KEY = get_clean_env("GEMINI_API_KEY")
CONSUMER_KEY = get_clean_env("CONSUMER_KEY")
CONSUMER_SECRET = get_clean_env("CONSUMER_SECRET")
ACCESS_TOKEN = get_clean_env("ACCESS_TOKEN")
ACCESS_TOKEN_SECRET = get_clean_env("ACCESS_TOKEN_SECRET")

# ==========================================
# 2. íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸
# ==========================================
client = None
try:
    client = tweepy.Client(
        consumer_key=CONSUMER_KEY,
        consumer_secret=CONSUMER_SECRET,
        access_token=ACCESS_TOKEN,
        access_token_secret=ACCESS_TOKEN_SECRET
    )
except:
    print("âš ï¸ íŠ¸ìœ„í„° í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì˜¤ë¥˜ (í‚¤ í™•ì¸ í•„ìš”)")

# ==========================================
# 3. AI í•¨ìˆ˜ (ëª¨ë¸ ìë™ íƒìƒ‰ ê¸°ëŠ¥ íƒ‘ì¬)
# ==========================================
def summarize_news(category, title, link):
    # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    list_url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GEMINI_API_KEY}"
    target_model = "gemini-1.5-flash" # ê¸°ë³¸ê°’

    try:
        # ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ë´…ë‹ˆë‹¤.
        list_res = requests.get(list_url)
        if list_res.status_code == 200:
            models = list_res.json().get('models', [])
            # 'generateContent' ê¸°ëŠ¥ì„ ì§€ì›í•˜ëŠ” ëª¨ë¸ ì°¾ê¸°
            for m in models:
                if 'generateContent' in m.get('supportedGenerationMethods', []):
                    # ëª¨ë¸ ì´ë¦„ì—ì„œ 'models/' ì œê±°
                    target_model = m['name'].replace('models/', '')
                    print(f"ğŸ¤– ë°œê²¬ëœ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸: {target_model}")
                    break # í•˜ë‚˜ ì°¾ìœ¼ë©´ ê·¸ê±¸ë¡œ ê²°ì •
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’({target_model}) ì‚¬ìš©")

    # 2. ì°¾ì€ ëª¨ë¸ë¡œ ìš”ì•½ ìš”ì²­
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{target_model}:generateContent?key={GEMINI_API_KEY}"
    
    prompt = f"ë‰´ìŠ¤ ì œëª©: {title}\në‰´ìŠ¤ ë§í¬: {link}\nì£¼ì‹ ë‰´ìŠ¤ 3ì¤„ ìš”ì•½ (í•´ìš”ì²´)."
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            print(f"âš ï¸ AI ìš”ì²­ ì‹¤íŒ¨ (ì½”ë“œ {response.status_code}): {response.text}")
            return None
    except Exception as e:
        print(f"âš ï¸ AI ì—°ê²° ì—ëŸ¬: {e}")
        return None

# ==========================================
# 4. ë‰´ìŠ¤ ì²˜ë¦¬ ë¡œì§
# ==========================================
RSS_SOURCES = [
    ("ë¯¸êµ­ì£¼ì‹(íˆ¬ì)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=15839069", "last_link_us_investing.txt"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸ˆìœµ)", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664", "last_link_us_finance.txt"),
    ("ë¯¸êµ­ì£¼ì‹(ê¸°ìˆ )", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=19854910", "last_link_us_tech.txt"),
    ("í•œêµ­ì£¼ì‹(í•œê²½)", "https://www.hankyung.com/feed/finance", "last_link_kr.txt")
]

def get_latest_news(rss_url):
    try:
        feed = feedparser.parse(rss_url)
        return feed.entries[0] if feed.entries else None
    except: return None

def check_if_new(last_link_file, current_link):
    if not os.path.exists(last_link_file): return True
    with open(last_link_file, 'r', encoding='utf-8') as f:
        return f.read().strip() != current_link

def save_current_link(last_link_file, current_link):
    with open(last_link_file, 'w', encoding='utf-8') as f:
        f.write(current_link)

if __name__ == "__main__":
    for category, rss_url, filename in RSS_SOURCES:
        print(f"\n--- [{category}] ---")
        news = get_latest_news(rss_url)
        
        if news and check_if_new(filename, news.link):
            print(f"âœ¨ ë‰´ìŠ¤ ë°œê²¬: {news.title}")
            
            summary = summarize_news(category, news.title, news.link)
            if not summary:
                print("ğŸš¨ AI ì‹¤íŒ¨. ì œëª©ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                summary = f"{news.title}\n(AI ì‘ë‹µ ì—†ìŒ)"

            tweet_text = f"[{category}] ğŸš¨\n\n{summary}\n\nğŸ”— {news.link}"
            
            try:
                client.create_tweet(text=tweet_text)
                print("âœ… íŠ¸ìœ— ì—…ë¡œë“œ ì„±ê³µ!")
                save_current_link(filename, news.link)
            except Exception as e:
                print(f"âŒ íŠ¸ìœ— ì‹¤íŒ¨: {e}")
                print("ğŸ‘‰ 402 ì—ëŸ¬ë¼ë©´: íŠ¸ìœ„í„° í”„ë¡œì íŠ¸ë¥¼ ì‚­ì œí•˜ê³  'Free'ë¡œ ë‹¤ì‹œ ë§Œë“œì„¸ìš”.")
        else:
            print("ìƒˆ ë‰´ìŠ¤ ì—†ìŒ.")
        time.sleep(1)
