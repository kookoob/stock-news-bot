import feedparser
import tweepy
import requests
import os
import sys
import time
import re # íƒœê·¸ ì œê±°ìš©

# ==========================================
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# ==========================================
try:
    GEMINI_API_KEY = os.environ["GEMINI_API_KEY"].strip()
    CONSUMER_KEY = os.environ["CONSUMER_KEY"].strip()
    CONSUMER_SECRET = os.environ["CONSUMER_SECRET"].strip()
    ACCESS_TOKEN = os.environ["ACCESS_TOKEN"].strip()
    ACCESS_TOKEN_SECRET = os.environ["ACCESS_TOKEN_SECRET"].strip()
except KeyError:
    print("âš ï¸ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì°¾ì§€ ëª»í•´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    sys.exit(1)

# ==========================================
# 2. ë‰´ìŠ¤ ì†ŒìŠ¤ ì„¤ì •
# ==========================================
RSS_US_INVESTING = "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=15839069"
RSS_US_FINANCE   = "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664"
RSS_US_TECH      = "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=19854910"
RSS_KR = "https://www.hankyung.com/feed/finance"

# ==========================================
# 3. íŠ¸ìœ„í„° ì¸ì¦
# ==========================================
try:
    client = tweepy.Client(
        consumer_key=CONSUMER_KEY,
        consumer_secret=CONSUMER_SECRET,
        access_token=ACCESS_TOKEN,
        access_token_secret=ACCESS_TOKEN_SECRET
    )
except Exception as e:
    print(f"âŒ íŠ¸ìœ„í„° ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ==========================================
# 4. ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# ==========================================
def clean_html(raw_html):
    """RSS ì„¤ëª…ê¸€ì— ìˆëŠ” ì§€ì €ë¶„í•œ íƒœê·¸ ì œê±°"""
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.strip()

def get_latest_news(rss_url):
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries:
            return None
        return feed.entries[0]
    except Exception as e:
        print(f"âš ï¸ RSS ë¡œë”© ì—ëŸ¬: {e}")
        return None

def check_if_new(last_link_file, current_link):
    if not os.path.exists(last_link_file):
        return True
    with open(last_link_file, 'r', encoding='utf-8') as f:
        last_link = f.read().strip()
    return last_link != current_link

def save_current_link(last_link_file, current_link):
    with open(last_link_file, 'w', encoding='utf-8') as f:
        f.write(current_link)

def summarize_news(category, title, link):
    # [1ì°¨ ì‹œë„] AIì—ê²Œ ìš”ì•½ ìš”ì²­
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    
    prompt = f"ë‰´ìŠ¤ ì œëª©: {title}\në‰´ìŠ¤ ë§í¬: {link}\nì´ ì£¼ì‹ ë‰´ìŠ¤ë¥¼ í•œêµ­ì–´ë¡œ 3ì¤„ ìš”ì•½í•´ì¤˜. í•´ìš”ì²´ë¡œ ì¹œì ˆí•˜ê²Œ."
    
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    try:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            print(f"âš ï¸ AI ì—°ê²° ì‹¤íŒ¨ (ì½”ë“œ {response.status_code}), ë¹„ìƒ ëª¨ë“œ ì „í™˜...")
            return None # ì‹¤íŒ¨í•˜ë©´ None ë¦¬í„´ -> ë¹„ìƒ ëª¨ë“œ ë°œë™
    except Exception:
        return None

# ==========================================
# 5. ë©”ì¸ ì‹¤í–‰
# ==========================================
def process_news(category_name, rss_url, last_link_file):
    print(f"\n--- [{category_name}] í™•ì¸ ì¤‘ ---")
    
    news = get_latest_news(rss_url)
    if not news:
        print("ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    if check_if_new(last_link_file, news.link):
        print(f"âœ¨ ìƒˆ ë‰´ìŠ¤ ë°œê²¬: {news.title}")
        
        # 1. AI ìš”ì•½ ì‹œë„
        summary = summarize_news(category_name, news.title, news.link)
        
        # 2. AI ì‹¤íŒ¨ ì‹œ ë¹„ìƒ ëª¨ë“œ (RSS ì„¤ëª…ê¸€ ì‚¬ìš©)
        if not summary:
            print("ğŸš¨ ë¹„ìƒ ëª¨ë“œ: AI ëŒ€ì‹  ì›ë¬¸ ì„¤ëª…ê¸€ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            raw_desc = news.get("summary", news.get("description", "ë‚´ìš© ì—†ìŒ"))
            summary = clean_html(raw_desc)[:120] + "..." # 120ìë¡œ ìë¥´ê¸°
            summary = f"{summary}\n(AI ì„œë²„ ì˜¤ë¥˜ë¡œ ì›ë¬¸ ìš”ì•½ì„ ì „ì†¡í•©ë‹ˆë‹¤ ğŸ¤–)"

        tweet_text = f"[{category_name} ì†ë³´] ğŸš¨\n\n{summary}\n\nğŸ”— ì›ë¬¸: {news.link}"
        
        try:
            client.create_tweet(text=tweet_text)
            print("âœ… íŠ¸ìœ— ì—…ë¡œë“œ ì„±ê³µ!")
            save_current_link(last_link_file, news.link)
        except Exception as e:
            print(f"âŒ íŠ¸ìœ— ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print("ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    process_news("ë¯¸êµ­ì£¼ì‹(íˆ¬ì)", RSS_US_INVESTING, "last_link_us_investing.txt")
    time.sleep(2)
    process_news("ë¯¸êµ­ì£¼ì‹(ê¸ˆìœµ)", RSS_US_FINANCE, "last_link_us_finance.txt")
    time.sleep(2)
    process_news("ë¯¸êµ­ì£¼ì‹(ê¸°ìˆ )", RSS_US_TECH, "last_link_us_tech.txt")
    time.sleep(2)
    process_news("í•œêµ­ì£¼ì‹(í•œê²½)", RSS_KR, "last_link_kr.txt")
