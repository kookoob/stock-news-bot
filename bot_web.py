#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì›¹ì‚¬ì´íŠ¸ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ (ì´ë¯¸ì§€ ì—†ì´)
"""

import feedparser
import requests
import os
import sys
import json
import time
from datetime import datetime, timezone
from bs4 import BeautifulSoup

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyDSkxDygLSc_UHOGzkKmegx_63ktbEtUYc")
OUTPUT_FILE = "../news-app/public/news.json"

RSS_SOURCES = [
    ("Reuters(Business)", "https://www.reuters.com/business/rss"),
    ("Reuters(Markets)", "https://www.reuters.com/markets/rss"),
    ("WSJ(Market)", "https://feeds.content.dowjones.io/public/rss/RSSMarketsMain"),
    ("Bloomberg", "https://feeds.bloomberg.com/markets/news.rss"),
    ("CNBC(Markets)", "https://www.cnbc.com/id/10000664/device/rss/rss.html"),
    ("Financial Times", "https://www.ft.com/rss/home"),
    ("MarketWatch", "https://feeds.marketwatch.com/marketwatch/marketpulse/"),
    ("Yahoo Finance", "https://finance.yahoo.com/news/rssindex"),
    ("Seeking Alpha", "https://seekingalpha.com/market_currents.xml"),
    ("CoinDesk", "https://www.coindesk.com/arc/outboundfeeds/rss/"),
]

def fetch_news():
    """ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘"""
    news_items = []
    
    # í•„í„°ë§í•  í‚¤ì›Œë“œ
    skip_words = ['quiz', 'poll', 'í€´ì¦ˆ', 'opinion', 'commentary', 'sponsored']
    
    for name, url in RSS_SOURCES:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:8]:  # ê° ì†ŒìŠ¤ì—ì„œ 8ê°œì”©
                title_lower = entry.title.lower()
                
                # í€´ì¦ˆ/ê´‘ê³  í•„í„°ë§
                if any(word in title_lower for word in skip_words):
                    continue
                
                news_items.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': name.split('(')[0],
                    'published': entry.get('published', ''),
                })
        except Exception as e:
            print(f"âŒ {name} ì˜¤ë¥˜: {e}")
    
    return news_items[:30]  # ìµœëŒ€ 30ê°œ

def translate_and_summarize(title, link):
    """Geminië¡œ ë²ˆì—­ ë° ìš”ì•½"""
    try:
        # ê¸°ì‚¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(link, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        paragraphs = soup.find_all('p')
        content = ' '.join([p.get_text() for p in paragraphs[:5]])[:1500]
        
        # Gemini API í˜¸ì¶œ
        prompt = f"""ë‹¤ìŒ ì˜ë¬¸ ë‰´ìŠ¤ë¥¼ í•œê¸€ë¡œ ë²ˆì—­í•˜ê³  íˆ¬ìì ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”.

ì œëª©: {title}
ë‚´ìš©: {content}

ê·œì¹™:
- ì œëª©ì€ í•œê¸€ë¡œë§Œ, ê°„ê²°í•˜ê²Œ 1ì¤„
- ìš”ì•½ì€ íˆ¬ì ê´€ì ìœ¼ë¡œ 2-3ë¬¸ì¥
- ìƒì„¸ ë‚´ìš©ì€ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ì¤‘ì‹¬ 3-4ë¬¸ë‹¨
- ê´€ë ¨ ì£¼ì‹/ì§€ìˆ˜/ì•”í˜¸í™”í í‹°ì»¤ ì¶”ì¶œ (ìµœëŒ€ 5ê°œ, ì˜ˆ: AAPL, ^DJI, BTC-USD)
- JSON í˜•ì‹ ì—„ìˆ˜

JSON:
{{"title_ko":"ë²ˆì—­ëœì œëª©","summary":"ìš”ì•½","content":"ìƒì„¸ë‚´ìš©","tickers":["AAPL","^DJI"]}}"""
        
        response = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}",
            headers={'Content-Type': 'application/json'},
            json={
                "contents": [{
                    "parts": [{"text": prompt}]
                }]
            },
            timeout=30
        )
        
        result = response.json()
        
        # ì—ëŸ¬ ì²´í¬
        if 'candidates' not in result or not result['candidates']:
            print(f"    âš ï¸  Gemini ì‘ë‹µ ì—†ìŒ: {result.get('error', 'Unknown')}")
            raise Exception("No candidates in response")
        
        text = result['candidates'][0]['content']['parts'][0]['text']
        
        # JSON íŒŒì‹± (ì œì–´ ë¬¸ì ì œê±°)
        import re
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            # ì œì–´ ë¬¸ì ì œê±°
            json_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', ' ', json_str)
            data = json.loads(json_str)
            return data
        
    except Exception as e:
        print(f"âŒ ë²ˆì—­/ìš”ì•½ ì‹¤íŒ¨: {e}")
        # ê°„ë‹¨í•œ ì œëª© ë²ˆì—­ì´ë¼ë„ ì‹œë„
        try:
            simple_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ì„ í•œê¸€ 1ì¤„ë¡œë§Œ ë²ˆì—­í•˜ì„¸ìš”. ì„¤ëª… ì—†ì´ ë²ˆì—­ë§Œ: {title}"
            resp = requests.post(
                f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}",
                headers={'Content-Type': 'application/json'},
                json={"contents": [{"parts": [{"text": simple_prompt}]}]},
                timeout=15
            )
            result = resp.json()
            if 'candidates' in result and result['candidates']:
                translated = result['candidates'][0]['content']['parts'][0]['text'].strip()
                # ì²« ì¤„ë§Œ ì‚¬ìš© (ì—¬ëŸ¬ ì˜µì…˜ ì œì‹œ ë°©ì§€)
                translated = translated.split('\n')[0].strip('*-"\'')
                return {
                    "title_ko": translated,
                    "summary": "ìƒì„¸ ìš”ì•½ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.",
                    "content": "ì›ë¬¸ì„ í™•ì¸í•˜ë ¤ë©´ ì•„ë˜ ë§í¬ë¥¼ í´ë¦­í•˜ì„¸ìš”.",
                    "tickers": []
                }
        except:
            pass
        
        return {
            "title_ko": title,
            "summary": "ìš”ì•½ ìƒì„± ì‹¤íŒ¨",
            "content": "ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "tickers": []
        }

def main():
    print("=" * 60)
    print("ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (Gemini)")
    print("=" * 60)
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    print("1ï¸âƒ£ RSS í”¼ë“œ ìˆ˜ì§‘ ì¤‘...")
    raw_news = fetch_news()
    print(f"âœ… {len(raw_news)}ê°œ ìˆ˜ì§‘")
    
    # ë²ˆì—­ ë° ìš”ì•½
    print("\n2ï¸âƒ£ Gemini ë²ˆì—­/ìš”ì•½ ì¤‘...")
    processed_news = []
    
    max_process = min(10, len(raw_news))  # ìµœëŒ€ 10ê°œ
    for i, item in enumerate(raw_news[:max_process], 1):
        print(f"   ì²˜ë¦¬ ì¤‘ {i}/{max_process}: {item['title'][:50]}...")
        result = translate_and_summarize(item['title'], item['link'])
        
        # í‹°ì»¤ ì¶”ì¶œ (Gemini + í‚¤ì›Œë“œ ë§¤í•‘)
        tickers = result.get('tickers', []) or []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í‹°ì»¤ ì¶”ê°€
        text = (result['title_ko'] + ' ' + result['content']).lower()
        if 'ì•”í˜¸í™”í' in text or 'ë¹„íŠ¸ì½”ì¸' in text or 'crypto' in item['title'].lower():
            tickers.extend(['BTC-USD', 'ETH-USD'])
        if 'ë‹¤ìš°ì¡´ìŠ¤' in text or 'dow jones' in item['title'].lower():
            tickers.extend(['^DJI', '^GSPC'])
        if 'ë‚˜ìŠ¤ë‹¥' in text or 'nasdaq' in item['title'].lower():
            tickers.append('^IXIC')
        if 'block' in item['title'].lower() or 'ë¸”ë¡' in text:
            tickers.append('SQ')
        if 'ê³¨ë“œë§Œ' in text or 'goldman' in item['title'].lower():
            tickers.append('GS')
        if 'ì• í”Œ' in text or 'apple' in item['title'].lower():
            tickers.append('AAPL')
        if 'í…ŒìŠ¬ë¼' in text or 'tesla' in item['title'].lower():
            tickers.append('TSLA')
        
        # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 5ê°œ
        tickers = list(set(tickers))[:5]
        
        processed_news.append({
            'id': f"news_{int(time.time())}_{i}",
            'title': result['title_ko'],
            'summary': result['summary'],
            'content': result['content'],
            'source': item['source'],
            'date': datetime.now().strftime('%Y-%m-%d %H:%M'),
            'timestamp': int(time.time()) - (i * 60),
            'link': item['link'],
            'tickers': tickers
        })
        
        time.sleep(2)  # API rate limit
    
    # ê¸°ì¡´ ë‰´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
    print("\n3ï¸âƒ£ ê¸°ì¡´ ë‰´ìŠ¤ ë³‘í•© ì¤‘...")
    existing_news = []
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                existing_news = json.load(f)
            print(f"   ê¸°ì¡´ ë‰´ìŠ¤: {len(existing_news)}ê°œ")
        except:
            pass
    
    # ì¤‘ë³µ ì œê±° (ë§í¬ ê¸°ì¤€)
    existing_links = {item['link'] for item in existing_news}
    new_items = [item for item in processed_news if item['link'] not in existing_links]
    
    print(f"   ìƒˆ ë‰´ìŠ¤: {len(new_items)}ê°œ (ì¤‘ë³µ {len(processed_news) - len(new_items)}ê°œ ì œê±°)")
    
    # ë³‘í•© ë° ìµœì‹ ìˆœ ì •ë ¬
    all_news = new_items + existing_news
    all_news.sort(key=lambda x: x['timestamp'], reverse=True)
    
    # ìµœëŒ€ 200ê°œë¡œ ì œí•œ
    all_news = all_news[:200]
    
    # JSON ì €ì¥
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(all_news, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ì™„ë£Œ! {OUTPUT_FILE}")
    print(f"ğŸ“Š ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ì €ì¥ (ìµœì‹  {len(new_items)}ê°œ ì¶”ê°€)")

if __name__ == "__main__":
    main()
